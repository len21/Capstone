Problem 5.
# Suppose that we have created a machine learning algorithm that predicts whether a link will be
# clicked with 99% sensitivity and 99% specificity. The rate the link is clicked is 1/1000 of
# visits to a website. If we predict the link will be clicked on a specific visit,
# what is the probability it will actually be clicked?
# 100,000 visits => 100 clicks
# 99% = sensitivity = TP/(TP+FN) = 99/(99+1) = 99/100
# 99% specificity =TN/(TN+FP) = 98901/(98901+999) = 98901/99900
# P(actually clicked|clicked) = TP/(TP+FP) = 99/(99+999) = 9%
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
library(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
library(caret)
install.packages("caret")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
library(ggplot2)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
training
?createDataPartition
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
dim(training)
str(training)
hist(training$Superplasticizer,main="",xlab="Superplasticizer")
qplot(CompressiveStrength, Cement, data=concrete)
index<-colnames(concrete[,c(1,2,3,4,5,6,7)])
featurePlot(x=training[,index], y=training$CompressiveStrength, plot="pairs")
summary(training)
summary(training)
index
featurePlot(x=training[,1-8], y=training$CompressiveStrength, plot="pairs")
featurePlot(x=training[,1-8], y=training$CompressiveStrength, plot="pairs")
qplot(CompressiveStrength, Cement, data=concrete)
hist(training$Superplasticizer,main="",xlab="Superplasticizer")
summary(training)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
featurePlot(x=training[,1-8], y=training$CompressiveStrength, plot="pairs")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
summary(training)
str(training)
ols_IL <- training[,grep('^IL', x = names(training) )]
Cols_IL <- training[,grep('^IL', x = names(training) )]
preObj <- preProcess(training[,Cols_IL],method=c("center","scale"))
preObj <- preProcess(Cols_IL, method=c("center","scale"))
preObj
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
ggplot(data = training, aes(x = training$Superplasticizer)) + geom_histogram() + theme_bw()
library(ggplot2)
ggplot(data = training, aes(x = training$Superplasticizer))
qp <- ggplot(data = training, aes(x = training$Superplasticizer))
qp
qplot(data = training, aes(x = training$Superplasticizer)) + geom_histogram() + theme_bw()
ggplot(data = training, aes(x = training$Superplasticizer))
Cols_IL <- grep("^IL", names(training), value = TRUE)
Cols_IL <- grep("^IL", names(training), value = TRUE)
preObj <- preProcess(training[, Cols_IL], method = "pca", thresh = 0.9)
preObj
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
Cols_IL <- grep("^IL", names(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
adData
View(adData)
View(adData)
predictors_IL <- adData[, IL_str]
predictors_IL <- adData[, Cols_IL]
df2 <- data.frame(diagnosis, predictors_IL)
predictors_IL <- training[, Cols_IL]
df2 <- data.frame(diagnosis, predictors_IL)
print(cartModel$finalModel)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
df1 <- segmentationOriginal
trainIndex <- df1$Case == "Train"
training = df1[trainIndex, ]
testing = df1[!trainIndex, ]
set.seed(125)
##
cartModel <- train(Class ~ ., data=training, method="rpart")
cartModel$finalModel
print(cartModel$finalModel)
plot(cartModel$finalModel, uniform=TRUE)
text(cartModel$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
fit <- train(Area~.,data=olive,method="rpart")
data(olive)
View(olive)
pred <- predict(fit,newdata)
pred
print(pred)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, method="glm", family="binomial")
summary(modelSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
predict.modelSA.test =  predict(modelSA, newdata=testSA)
table(predict.modelSA.test>0.5, testSA$chd)
missClass(testSA$chd, predict(model, newdata = testSA))
missClass(testSA$chd, predict(modelSA , newdata = testSA))
missClass(trainSA$chd, predict(modelSA , newdata = trainSA))
missClass(testSA$chd, predict(modelSA , newdata = testSA))
missClass(trainSA$chd, predict(modelSA , newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train)
dim(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
install.packages("randomForest", dependencies = TRUE)
library(randomForest)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
library(ElemStatLearn)
sessionInfo()
data(vowel.train)
data(vowel.test)
data(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
fitRf <- train(y ~ ., data=vowel.train, method="rf")
library(caret)
sessionInfo()
set.seed(33833)
fitRf <- train(y ~ ., data=vowel.train, method="rf")
library(randomForest)
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitRf
print(fitRF)
print(fitRf)
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
predRf
confusionMatrix(predRf, vowel.test$y)
confusionMatrix(predRf, vowel.test$y)$overall[1]
confusionMatrix(predRf, vowel.test$y)$overall['Accuracy']
confusionMatrix(predGBM vowel.test$y)$overall['Accuracy']
confusionMatrix(predGBM, vowel.test$y)$overall['Accuracy']
confusionMatrix(predRf, vowel.test$y)$overall['Accuracy']
confusionMatrix(predGBM, vowel.test$y)$overall['Accuracy']
data(vowel.train)
data(vowel.test)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
confusionMatrix(predRf, vowel.test$y)$overall['Accuracy']
confusionMatrix(predGBM, vowel.test$y)$overall['Accuracy']
predboth <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
predboth
accuracy <- sum(predRf[predboth$agree] == predboth$y[predboth$agree]) / sum(predboth$agree)
accuracy
predboth <- (predRf == predGBM)
confusionMatrix(vowel.test$y[predboth], predRf[predboth])$overall['Accuracy']
library(caret)
library(gbm)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fitRf <- train(diagnosis ~ ., data=training, method="rf")
fitGBM <- train(diagnosis ~ ., data=training, method="gbm")
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
library(MASS)
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
predStack <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
fitAll <- train(diagnosis ~., data=predStack, method="rf")
predFit <- predict(fitAll, testing)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fitRf <- train(diagnosis ~ ., data=training, method="rf")
fitGBM <- train(diagnosis ~ ., data=training, method="gbm")
library(MASS)
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
predStack <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
fitAll <- train(diagnosis ~., data=predStack, method="rf")
predFit <- predict(fitAll, testing)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
fit
plot.enet(fit$finalModel, xvar="penalty", use.color=T)
library(lubridate)
install.packages("lubridate")
library(lubridate)
dat = read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv")
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(fileUrl, destfile="./data/gaData.csv")
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(fileUrl, destfile="./data/gaData.csv")
library(lubridate)
dat = read.csv("./data/gaData.csv")
setwd("/Users/moiralennox/Documents/IT Documents/Data Science Class/DS8 - Machine Learning")
dat = read.csv("./Data/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstrain = ts(training$visitsTumblr)
head(tstrain)
dim(tstrain)
fit <- bats(tstrain)
library(forecast)
install.packages("forecast")
library(forecast)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
prop.table(table(predComb$in95))[2]
h <- dim(testing)[1]
fcast <- forecast(fit, level = 95, h = h)
accuracy(fcast, testing$visitsTumblr)
result <- c()
l <- length(fcast$lower)
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
result <- c()
l <- length(fcast$lower)
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
sum(result)/l * 100
result <- c()
l <- length(fcast$lower)
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
pred <- forecast(fit, length(testing$visitsTumblr))
pred <- cbind(testing, data.frame(pred))
pred$isIn95 <- pred$Lo.95 < pred$visitsTumblr & pred$visitsTumblr < pred$Hi.95
prop.table(table(pred$isIn95))
set.seed(325)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
require(e1071)
fit <- svm(CompressiveStrength ~ ., data=training)
testing$hat <- predict(fit, testing)
testing$error <- testing$CompressiveStrength - testing$hat
rmse <- sqrt(mean(testing$error ^ 2))
rmse
set.seed(325)
fit <- svm(CompressiveStrength ~., data=training)
pred <- predict(fit, testing)
acc <- accuracy(pred, testing$CompressiveStrength)
acc
install.packages("devtools")
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(slidify)
library(slidify)
shiny::runApp('~/Documents/IT Documents/Data Science Class/DS9 - Developing Data Products/CarsApp')
log(1)
log(0)
log10(1)
log10(100)
log10(0)
log10(0)
log10(0 + 1)
log10(3 + 1)
log10(3)
log10(4)
```{r setup,echo=FALSE, warning=FALSE, message=FALSE}
require(cowplot)
install.packages("cowplot")
library(knitr)
library(data.table)
library(car)
library(sandwich)
library(msm)
require(pscl) # ZINB model
library(plyr)
library(ggplot2)
setwd("/Users/moiralennox/GitHub/Capstone")
load(file = "dt_merge.rda")
#subset to years of 2008-2015
dt_merge_pet <- subset(dt_merge, revyear!=2015 & revyear!=2004 & revyear!=2005 & revyear!=2006 & revyear!=2007)
dt_merge_pet$revyear = factor(dt_merge_pet$revyear)
dt_merge_pet$country = factor(dt_merge_pet$country)
# Created just for box plot and regression
dt_merge_pet2 <- subset(dt_merge_pet, dogsallowed== TRUE &revyear!=2015 & revyear!=2004 & revyear!=2005 & revyear!=2006 & revyear!=2007)
rm(dt_merge)
require(cowplot)
plot1 <- ggplot(dt_merge_pet2, aes(petcount, fill = revyear)) +
ggtitle("Fig 1. # Petcount Reviews") +
geom_histogram(binwidth=.5, position="dodge")
plot2 <- ggplot(dt_merge_pet2, aes(petcount)) + geom_histogram() +
ggtitle("Fig 2. log(# Petcount Reviews)") + scale_x_log10()
plot_grid(plot1, plot2, align='h', labels=c('Fig 1. # Petcount Reviews', 'Fig 2. log(# Petcount Reviews)'))
plot_grid(plot1, plot2, align='h')
# Print plots side by side
pairs(~dogsallowed+petcount+revcount+revyear+maincat+country+votefuncount+voteusefulcount+votecoolcount+starsavg,
data=dt_merge_pet,
lower.panel=panel.smooth,
upper.panel=panel.cor,
diag.panel=panel.hist,
main="Scatterplot Matrix")
panel.cor <- function(x, y, digits=2, cex.cor)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y))
txt <- format(c(r, 0.123456789), digits=digits)[1]
test <- cor.test(x,y)
Signif <- ifelse(round(test$p.value,3)<0.001,"p<0.001",paste("p=",round(test$p.value,3)))
text(0.5, 0.25, paste("r=",txt))
text(.5, .75, Signif)
}
panel.smooth<-function (x, y, col = "blue", bg = NA, pch = 18,
cex = 0.8, col.smooth = "red", span = 2/3, iter = 3, ...)
{
points(x, y, pch = pch, col = col, bg = bg, cex = cex)
ok <- is.finite(x) & is.finite(y)
if (any(ok))
lines(stats::lowess(x[ok], y[ok], f = span, iter = iter),
col = col.smooth, ...)
}
panel.hist <- function(x, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col="cyan", ...)
}
pairs(~dogsallowed+petcount+revcount+revyear+maincat+country+votefuncount+voteusefulcount+votecoolcount+starsavg,
data=dt_merge_pet,
lower.panel=panel.smooth,
upper.panel=panel.cor,
diag.panel=panel.hist,
main="Scatterplot Matrix")
library(png)
library(grid)
img <- readPNG(/Users/moiralennox/GitHub/Capstone/Scatterplot_Matrix.png)
grid.raster(img)
img <- readPNG("/Users/moiralennox/GitHub/Capstone/Scatterplot_Matrix.png"")
img <- readPNG("/Users/moiralennox/GitHub/Capstone/Scatterplot_Matrix.png")
setwd("/Users/moiralennox/GitHub/Capstone")
img <- readPNG("Scatterplot_Matrix.png")
grid.raster(img)
date: "November 22nd, 2015"
setwd("/Users/moiralennox/GitHub/Capstone")
img <- readPNG("Scatterplot_Matrix.png")
grid.raster(img)
sumdata2 <- ddply(dt_merge_pet2, c("country", "revyear"), summarise,
N    = length(petcount),
mean = mean(petcount),
sd   = sd(petcount),
se   = sd / sqrt(N))
sumdata2
---
fit3 <- zeroinfl(petcount~revcount+revyear+votefuncount+voteusefulcount+
+starsavg+country|revcount+revyear+votefuncount+voteusefulcount+
+starsavg+country,data = dt_merge_pet2, dist = "negbin", EM = TRUE)
expCoef <- exp(coef((fit3)))
expCoef <- matrix(expCoef, ncol = 2)
rownames(expCoef) <- names(coef(fit3))
colnames(expCoef) <- c("Count_Model","Zero_Model")
expCoef
coef(fit3)
names(coef(fit3))
rownames(expCoef)
rownames(expCoef) <- names(coef(fit3))
names(coef(fit3))
rownames(expCoef) <- names(c("Intercept","revcount","revyear2009",",revyear2010","revyear2011","revyear2012",
"revyear2013","revyear2014" "votefuncount","voteusefulcount","starsavg","countryDEU",
"countryUK","countryUSA"))
rownames(expCoef) <- c("Intercept","revcount","revyear2009",",revyear2010","revyear2011","revyear2012",
"revyear2013","revyear2014" "votefuncount","voteusefulcount","starsavg","countryDEU","countryUK","countryUSA")
rownames(expCoef) <- c("Intercept","revcount","revyear2009",",revyear2010","revyear2011","revyear2012","revyear2013","revyear2014" "votefuncount","voteusefulcount","starsavg","countryDEU","countryUK","countryUSA")
rownames(expCoef) <- c("Intercept","revcount","revyear2009",",revyear2010","revyear2011","revyear2012","revyear2013","revyear2014","votefuncount","voteusefulcount","starsavg","countryDEU","countryUK","countryUSA")
colnames(expCoef) <- c("Count_Model","Zero_Model")
expCoef
summary(fit3)
coef(fit3)
exp(coef(fit3))
expCoef <- exp(coef((fit3)))
expCoef
expCoef <- matrix(expCoef, ncol = 2)
expCoef
expCoef <- exp(coef((fit3)))
expCoef <- matrix(expCoef, ncol = 2)
rownames(expCoef) <- c("Intercept","revcount","revyear2009","revyear2010","revyear2011","revyear2012","revyear2013","revyear2014","votefuncount","voteusefulcount","starsavg","countryDEU","countryUK","countryUSA")
colnames(expCoef) <- c("Count_Model","Zero_Model")
expCoef

---
title: "Final Capstone Project"
author: "Moira Lennox"
date: "November 22nd, 2015"
output: pdf_document
---

```{r setup,echo=FALSE, warning=FALSE, message=FALSE} 
# get packages that are needed
library(knitr)
library(data.table)
library(car) 
library(cowplot)
library(sandwich)
library(msm)
require(pscl) # ZINB model
library(plyr)
library(ggplot2)
library(png)
library(grid)

```

## Title & Introduction
The data set for this capstone project was supplied by Yelp and is a subset of data for the years 2004 – 2015 and contains a number of counties. The yelp data supplied was made up of 5 files namely: reviews, business, user, tips, checkin. My work will focus on only two files namely the review and business files. My objective for this report is to analyze the “yelp” data set by exploring and researching the relationship between sets of variables and the business attribute that identifies as “dogallowed” to see if I could answer the question(s) below. 

Dogs can be a major part of the family. We love taking our dog everywhere with us, however she is not always welcome. So here is my question: Can the dataset tell me if there was a trend in welcoming pets into various businesses? I plan to narrow my focus down to two major categories hotels and restaurants since these are the areas I care about the most. I am going to look at the review data from 2008-2014. I will compare business that allow dogs to business that do not and then try to correlate those counts to dog references I find from data mining the review text for those references. I will look at the country trends to see if locations makes a difference.

## Data processing and Transformation
I read in the json files for Business and Review, flatten them created a few new columns namely: main category, country and review year. I aggregated the review data up to the business level. The final step was mergeing the dataset into a single dataset. 

```{r setup2 ,echo=FALSE, cache=TRUE, warning=FALSE}
setwd("/Users/moiralennox/GitHub/Capstone")
load(file = "dt_merge.rda")
#subset to years of 2008-2015
dt_merge_pet <- subset(dt_merge, revyear!=2015 & revyear!=2004 & revyear!=2005 & revyear!=2006 & revyear!=2007)
# update the factors after subset
dt_merge_pet$revyear = factor(dt_merge_pet$revyear)
dt_merge_pet$country = factor(dt_merge_pet$country)

# Created just for box plot and regression
dt_merge_pet2 <- subset(dt_merge_pet, dogsallowed== TRUE &revyear!=2015 & revyear!=2004 & revyear!=2005 & revyear!=2006 & revyear!=2007)

# remove dataset not used
rm(dt_merge)
```

```{r setup3 ,echo=TRUE}
str(dt_merge_pet)
```

## Exploratory Data Analysis
A quick histogram revealed that the pet review count data are heavily
Skewed. This means we will need to transform the data when we apply the various
models.

```{r da1,echo=FALSE, warning=FALSE, message=FALSE}
# The discrete response variable.
plot1 <- ggplot(dt_merge_pet2, aes(petcount, fill = revyear)) +
    ggtitle("Fig 1. # Petcount Reviews") +
    geom_histogram(binwidth=.5, position="dodge")
# Log transformed response variable.
plot2 <- ggplot(dt_merge_pet2, aes(petcount)) + geom_histogram() + 
    ggtitle("Fig 2. log(# Petcount Reviews)") + scale_x_log10()
# Print plots side by side
plot_grid(plot1, plot2, align='h')

```

I quick look at the summary data for the petcount shows and consistent increase year over year. So we could make the initial assumption that pets are increasing being mentioned for pet friendly businesses and maybe this is implying that there might be an increase in pet friendly places.

```{r da2,echo=FALSE}
sumdata <- ddply(dt_merge_pet2, c("revyear"), summarise,
               N    = length(petcount),
               mean = mean(petcount),
               sd   = sd(petcount),
               se   = sd / sqrt(N))
sumdata
```

I did a boxplot and scatterplot matrix to see if there might be linear correlation between multiple variables. I used this is will help me pinpointing specific variables that might have similar correlations to my dogsalloed petcount data. I looked at the correlation and it is not very strong but revcount shows the best correlation with voteusefulcount a close second.

## Methods and Data
I tested three differnt models from the GLM family and show my outcomes. As a result of my initial data analysis I have selected to use a Zero-inflated negative binomial model for modeling the data. This model works well for count variables with excessive zeros. There is 45% response of zero for petcount variable. 

```{r rm1a,echo=TRUE,warning=FALSE, message=FALSE}
# Look at three types of models
fit1 <- glm(petcount~revcount+revyear+country+votefuncount+voteusefulcount+
                +starsavg, data=dt_merge_pet2,family=poisson(link=log))

fit2 <- zeroinfl(petcount~revcount+revyear+votefuncount+voteusefulcount+
                +starsavg+country|revcount+revyear+votefuncount+voteusefulcount+
                +starsavg+country,data=dt_merge_pet2)

fit3 <- zeroinfl(petcount~revcount+revyear+votefuncount+voteusefulcount+
                +starsavg+country|revcount+revyear+votefuncount+voteusefulcount+
                +starsavg+country,data = dt_merge_pet2, dist = "negbin", EM = TRUE)
```

The Vuong test compares the three models and we can see that the test statistic is significant, for model three which indicates that the zero-inflated model is best model for the job.

All of the predictors in both the count and inflation portions of the model are statistically significant. This model fits the data significantly better than the null model, i.e., the intercept-only mode. To show that this is the case, we can compare with the current model to a null model without predictors using chi-squared test on the difference of log likelihoods, see below.

```{r rm1c,echo=TRUE}
mnull <- update(fit3, . ~ 1)
pchisq(2 * (logLik(fit3) - logLik(mnull)), df = 6, lower.tail = FALSE)
```

Review the results from model three which was selected.

```{r rm2,echo=FALSE}
summary(fit3)
## Exponentiated coefficients
expCoef <- exp(coef((fit3)))
expCoef <- matrix(expCoef, ncol = 2)
rownames(expCoef) <- c("Intercept","revcount","revyear2009","revyear2010","revyear2011","revyear2012","revyear2013","revyear2014","votefuncount","voteusefulcount","starsavg","countryDEU","countryUK","countryUSA") 
colnames(expCoef) <- c("Count_Model","Zero_Model")
expCoef
```

## Results
The average pet count is 4.6. One unit increase in revcount increases the average pet count increase by 1.01 times. The revyear(s) show a general increase year over year. One unit increase in UK increases the average pet count increase by 2.25 times, followed by USA by 1.51

## Discussion & Conclusion
I took a very simplistic approach and extracted words like "pet"and "dog" to create a new variable from the review text data so that it could be explored. That said I do believe having better designed features will almost always guarantee better result. Even thou there was not a very strong correlation between the petcount and the other predictors there seems to be some indication that there is an increase in commentaty around pets and dogs which might indicate that there might be an increase on dog friendly places.
As for country location the UK seemed to lead all the other locations for show an increase in the correlation.

## Appendix
Scatterplot Matrix used for exploratory data analysis.

```{r fig.width=10, fig.height=10,echo=FALSE}
setwd("/Users/moiralennox/GitHub/Capstone")
img <- readPNG("Scatterplot_Matrix.png")
grid.raster(img)

```

The Vuong test compares the three models to show which is the best model for the job.

```{r a2, echo=TRUE, eval=FALSE}
# Model 3 is the best model
vuong(fit1, fit2) 
vuong(fit2, fit3)  
vuong(fit1, fit3)

```

```{r da3,echo=TRUE, eval=FALSE}
# Correlations
cor1 <- with(dt_merge_pet2, cor.test(petcount, revcount))
cor2 <- with(dt_merge_pet2, cor.test(petcount, voteusefulcount))

```

